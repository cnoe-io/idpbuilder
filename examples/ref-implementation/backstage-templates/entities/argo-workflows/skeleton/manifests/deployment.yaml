# apiVersion: argoproj.io/v1alpha1
# kind: Workflow
# metadata:
#   name: ${{values.name}}
#   namespace: argo
#   labels:
#     env: dev
#     entity-id: ${{values.name}}
# spec:
#   serviceAccountName: admin
#   entrypoint: whalesay
#   templates:
#   - name: whalesay
#     container:
#       image: docker/whalesay:latest
#       command: [cowsay]
#       args: ["hello world"]
---
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: ${{values.name}}
  namespace: argo
  labels:
    env: dev
    entity-id: ${{values.name}}
spec:
  serviceAccountName: admin
  entrypoint: main
  action: create
  templates:
    - name: main
      steps:
        - - name: spark-job
            template: spark-job
        - - name: wait
            template: wait
            arguments:
              parameters:
              - name: spark-job-name
                value: '{{steps.spark-job.outputs.parameters.spark-job-name}}'

    - name: wait
      inputs:
        parameters:
          - name: spark-job-name
      resource:
        action: get
        successCondition: status.applicationState.state == COMPLETED
        failureCondition: status.applicationState.state == FAILED
        manifest: |
          apiVersion: "sparkoperator.k8s.io/v1beta2"
          kind: SparkApplication
          metadata:
            name: {{inputs.parameters.spark-job-name}}
            namespace: argo

    - name: spark-job
      outputs:
        parameters:
          - name: spark-job-name
            valueFrom:
              jsonPath: '{.metadata.name}'
      resource:
        action: create
        setOwnerReference: true
        manifest: |
          apiVersion: "sparkoperator.k8s.io/v1beta2"
          kind: SparkApplication
          metadata:
            name: spark-pi-${{values.name}}
            namespace: argo
            labels:
              env: dev
              entity-id: ${{values.name}}
          spec:
            type: Scala
            mode: cluster
            image: "docker.io/apache/spark:v3.1.3"
            imagePullPolicy: IfNotPresent
            mainClass: org.apache.spark.examples.SparkPi
            mainApplicationFile: "local:///opt/spark/examples/jars/spark-examples_2.12-3.1.3.jar"
            sparkVersion: "3.1.1"
            restartPolicy:
              type: Never
            volumes:
              - name: "test-volume"
                hostPath:
                  path: "/tmp"
                  type: Directory
            driver:
              cores: 1
              coreLimit: "1200m"
              memory: "512m"
              labels:
                version: 3.1.1
              serviceAccount: admin
              volumeMounts:
                - name: "test-volume"
                  mountPath: "/tmp"
            executor:
              cores: 1
              instances: 1
              memory: "512m"
              labels:
                version: 3.1.1
              volumeMounts:
                - name: "test-volume"
                  mountPath: "/tmp"
